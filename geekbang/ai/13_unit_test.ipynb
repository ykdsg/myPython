{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 第一步，解释功能代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import openai, load_api_key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T17:34:50.893790Z",
     "end_time": "2023-04-21T17:34:51.342099Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we use the `divmod` function to get the quotient and remainder of `seconds` divided by `60`. This gives us the number of minutes and seconds.\n",
      "- Next, we do the same thing with minutes and hours.\n",
      "- Finally, we use string formatting to return a string with the appropriate units.\n"
     ]
    }
   ],
   "source": [
    "# 对 stop 做了特殊的设置，只要连续两个换行或者类似连续两个换行的情况出现，就中止数据的生成。\n",
    "# 这是避免模型一口气连测试代码也生成出来。那样的话，我们没法对测试代码的生成提出具体的要求。\n",
    "def gpt35(prompt, model=\"text-davinci-002\", temperature=0.4, max_tokens=1000,\n",
    "          top_p=1, stop=[\"\\n\\n\", \"\\n\\t\\n\", \"\\n    \\n\"]):\n",
    "    response = openai.Completion.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p,\n",
    "        stop=stop\n",
    "    )\n",
    "    message = response[\"choices\"][0][\"text\"]\n",
    "    return message\n",
    "\n",
    "\n",
    "# 代码也可以让AI 生成\n",
    "code = \"\"\"\n",
    "def format_time(seconds):\n",
    "    minutes, seconds = divmod(seconds, 60)\n",
    "    hours, minutes = divmod(minutes, 60)\n",
    "\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h{minutes}min{seconds}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}min{seconds}s\"\n",
    "    else:\n",
    "        return f\"{seconds}s\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def explain_code(function_to_test, unit_test_package=\"pytest\"):\n",
    "    prompt = f\"\"\"\"# How to write great unit tests with {unit_test_package}\n",
    "\n",
    "In this advanced tutorial for experts, we'll use Python 3.10 and `{unit_test_package}` to write a suite of unit tests to verify the behavior of the following function.\n",
    "```python\n",
    "{function_to_test}\n",
    "```\n",
    "\n",
    "Before writing any unit tests, let's review what each element of the function is doing exactly and what the author's intentions may have been.\n",
    "- First,\"\"\"\n",
    "    response = gpt35(prompt)\n",
    "    return response, prompt\n",
    "\n",
    "\n",
    "code_explaination, prompt_to_explain_code = explain_code(code)\n",
    "print(code_explaination)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T17:34:54.838490Z",
     "end_time": "2023-04-21T17:34:57.778357Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第二步，设计测试用例"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normal behavior:\n",
      "    - `format_time(0)` should return `\"0s\"`\n",
      "    - `format_time(1)` should return `\"1s\"`\n",
      "    - `format_time(59)` should return `\"59s\"`\n",
      "    - `format_time(60)` should return `\"1min0s\"`\n",
      "    - `format_time(61)` should return `\"1min1s\"`\n",
      "    - `format_time(3599)` should return `\"59min59s\"`\n",
      "    - `format_time(3600)` should return `\"1h0min0s\"`\n",
      "    - `format_time(3601)` should return `\"1h0min1s\"`\n",
      "- Invalid inputs:\n",
      "    - `format_time(None)` should raise a `TypeError`\n",
      "    - `format_time(\"foo\")` should raise a `TypeError`\n",
      "    - `format_time(-1)` should raise a `ValueError`\n"
     ]
    }
   ],
   "source": [
    "def generate_a_test_plan(full_code_explaination, unit_test_package=\"pytest\"):\n",
    "    prompt_to_explain_a_plan = f\"\"\"\n",
    "\n",
    "A good unit test suite should aim to:\n",
    "- Test the function's behavior for a wide range of possible inputs\n",
    "- Test edge cases that the author may not have foreseen\n",
    "- Take advantage of the features of `{unit_test_package}` to make the tests easy to write and maintain\n",
    "- Be easy to read and understand, with clean code and descriptive names\n",
    "- Be deterministic, so that the tests always pass or fail in the same way\n",
    "\n",
    "`{unit_test_package}` has many convenient features that make it easy to write and maintain unit tests. We'll use them to write unit tests for the function above.\n",
    "\n",
    "For this particular function, we'll want our unit tests to handle the following diverse scenarios (and under each scenario, we include a few examples as sub-bullets):\n",
    "-\"\"\"\n",
    "    prompt = full_code_explaination + prompt_to_explain_a_plan\n",
    "    response = gpt35(prompt)\n",
    "    return response, prompt\n",
    "\n",
    "\n",
    "test_plan, prompt_to_get_test_plan = generate_a_test_plan(prompt_to_explain_code + code_explaination)\n",
    "print(test_plan)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T19:06:24.719769Z",
     "end_time": "2023-04-21T19:06:30.506044Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 第三步，撰写单元测试"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@pytest.mark.parametrize(\"seconds,expected_result\", [\n",
      "    # Normal behavior\n",
      "    (0, \"0s\"),\n",
      "    (1, \"1s\"),\n",
      "    (59, \"59s\"),\n",
      "    (60, \"1min0s\"),\n",
      "    (61, \"1min1s\"),\n",
      "    (3599, \"59min59s\"),\n",
      "    (3600, \"1h0min0s\"),\n",
      "    (3601, \"1h0min1s\"),\n",
      "    # Invalid inputs\n",
      "    (None, TypeError),\n",
      "    (\"foo\", TypeError),\n",
      "    (-1, ValueError)\n",
      "])\n",
      "def test_format_time(seconds, expected_result):\n",
      "    \"\"\"\n",
      "    This test verifies that the format_time function behaves as expected.\n",
      "    \"\"\"\n",
      "    if isinstance(expected_result, type) and issubclass(expected_result, Exception):\n",
      "        # If expected_result is an exception, we expect the function to raise it\n",
      "        with pytest.raises(expected_result):\n",
      "            format_time(seconds)\n",
      "    else:\n",
      "        # Otherwise, we expect the function to return the expected result\n",
      "        assert format_time(seconds) == expected_result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_test_cases(function_to_test, unit_test_package=\"pytest\"):\n",
    "    starter_comment = \"Below, each test case is represented by a tuple passed to the @pytest.mark.parametrize decorator\"\n",
    "    prompt_to_generate_the_unit_test = f\"\"\"\n",
    "\n",
    "Before going into the individual tests, let's first look at the complete suite of unit tests as a cohesive whole. We've added helpful comments to explain what each line does.\n",
    "```python\n",
    "import {unit_test_package}  # used for our unit tests\n",
    "\n",
    "{function_to_test}\n",
    "\n",
    "#{starter_comment}\"\"\"\n",
    "    full_unit_test_prompt = prompt_to_explain_code + code_explaination + test_plan + prompt_to_generate_the_unit_test\n",
    "    return gpt35(model=\"text-davinci-003\", prompt=full_unit_test_prompt, stop=\"```\"), prompt_to_generate_the_unit_test\n",
    "\n",
    "\n",
    "unit_test_response, prompt_to_generate_the_unit_test = generate_test_cases(code)\n",
    "print(unit_test_response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-21T19:14:14.890053Z",
     "end_time": "2023-04-21T19:14:28.765026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code_start_index = prompt_to_generate_the_unit_test.find(\"```python\\n\") + len(\"```python\\n\")\n",
    "code_output = prompt_to_generate_the_unit_test[code_start_index:] + unit_test_response\n",
    "# 打印完整代码\n",
    "print(code_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
